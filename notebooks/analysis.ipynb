{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-SQL Evaluation Results Analysis\n",
        "\n",
        "This notebook analyzes the evaluation results from baseline and finetuned models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().resolve().parent))\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load results\n",
        "results_dir = Path(\"../results\")\n",
        "\n",
        "# Find baseline and finetuned results\n",
        "baseline_files = list(results_dir.glob(\"evaluation_*_baseline.json\"))\n",
        "finetuned_files = list(results_dir.glob(\"evaluation_*_finetuned.json\"))\n",
        "\n",
        "baseline_results = None\n",
        "finetuned_results = None\n",
        "\n",
        "if baseline_files:\n",
        "    with open(sorted(baseline_files)[-1], 'r') as f:\n",
        "        baseline_results = json.load(f)\n",
        "    print(\"Baseline results loaded\")\n",
        "else:\n",
        "    print(\"No baseline results found\")\n",
        "\n",
        "if finetuned_files:\n",
        "    with open(sorted(finetuned_files)[-1], 'r') as f:\n",
        "        finetuned_results = json.load(f)\n",
        "    print(\"Finetuned results loaded\")\n",
        "else:\n",
        "    print(\"No finetuned results found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare metrics\n",
        "if baseline_results and finetuned_results:\n",
        "    metrics_comparison = pd.DataFrame({\n",
        "        'Baseline': baseline_results['metrics'],\n",
        "        'Finetuned': finetuned_results['metrics']\n",
        "    })\n",
        "    \n",
        "    metrics_comparison['Improvement'] = (\n",
        "        metrics_comparison['Finetuned'] - metrics_comparison['Baseline']\n",
        "    )\n",
        "    \n",
        "    print(metrics_comparison)\n",
        "    \n",
        "    # Plot comparison\n",
        "    ax = metrics_comparison[['Baseline', 'Finetuned']].plot(kind='bar')\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Metric')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
